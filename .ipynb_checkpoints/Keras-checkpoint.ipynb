{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## used for folders/files searching and path finding\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## sound preparation, feature extraction, preprocessing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "## math and charts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import math\n",
    "\n",
    "## some time measurement\n",
    "import time\n",
    "\n",
    "## data read/write with hdf5 files\n",
    "import h5py\n",
    "\n",
    "## random lmao\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO:\n",
    "\n",
    "RCNN\n",
    "DELETE SOME CODE\n",
    "ADD VISUALIZATION METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hop 10ms, window 40\n",
    "## OUTDATED, LOOK APPENDTRACKS FOR ITS REPLACEMENT\n",
    "## TO BE DELETED\n",
    "def appendSounds(data,labels,fp):\n",
    "    X, sr = sf.read(fp)\n",
    "    sound = np.array(X)\n",
    "    # librosa operates on (lenght, channels) matrices, wheras soundfile gave us (channels, lenght) \n",
    "    # so we transpose\n",
    "    sound = np.transpose(sound)\n",
    "    sound = librosa.core.to_mono(sound)\n",
    "    # resample so every wave has same sampling rate\n",
    "    sound = librosa.core.resample(sound, sr, 10000)\n",
    "    # set class number\n",
    "    classNumber = int(fp.split(\"/\")[1].split(\"-\")[1])\n",
    "    # compute and set mel spectrogram\n",
    "    D = np.abs(librosa.stft(sound, hop_length=506,  win_length=1024))**2\n",
    "    mel = librosa.logamplitude(librosa.feature.melspectrogram(S=D, sr=10000, n_mels = 64),ref_power= np.max)\n",
    "    iterator = 0\n",
    "    while iterator+16<=mel.shape[1]:\n",
    "        data.append(mel[:,iterator:iterator+16].flatten())\n",
    "        labels.append(classNumber)\n",
    "        iterator+=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hop 10ms, window 40\n",
    "def appendTracks(data,labels,fp):\n",
    "    X, sr = sf.read(fp)\n",
    "    sound = np.array(X)\n",
    "    # librosa operates on (lenght, channels) matrices, wheras soundfile gave us (channels, lenght) \n",
    "    # so we transpose\n",
    "    sound = np.transpose(sound)\n",
    "    sound = librosa.core.to_mono(sound)\n",
    "    # resample so every wave has same sampling rate\n",
    "    sound = librosa.core.resample(sound, sr, 10000)\n",
    "    # set class number\n",
    "    classNumber = int(fp.split(\"/\")[1].split(\"-\")[1])\n",
    "    # compute and set mel spectrogram\n",
    "    D = np.abs(librosa.stft(sound, hop_length=506,  win_length=1024))**2\n",
    "    mel = librosa.logamplitude(librosa.feature.melspectrogram(S=D, sr=10000, n_mels = 64),ref_power= np.max)\n",
    "    data.append(mel)\n",
    "    labels.append(classNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm done, time was: 389.736155987\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Lock, Pipe,Event\n",
    "\n",
    "## DO NOT USE IF HDF5 FILE HAS BEEN ALREADY CREATED!!!\n",
    "\n",
    "## whole thing is init method which preprocesses data and puts it into hdf5 file\n",
    "## only mel scaled spectrograms and classes of sound clips are preserved\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "## per process method, extracts data from given fold and sends it to main process\n",
    "def add(x,c):\n",
    "    tempdata,templabels = [],[]\n",
    "    for file in glob.glob(x):\n",
    "        appendTracks(tempdata, templabels, file)\n",
    "            \n",
    "    c.send(zip(tempdata, templabels))\n",
    "    del tempdata,templabels\n",
    "        \n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threads= []\n",
    "    connections=[0]*10\n",
    "    \n",
    "    \n",
    "    ## create threads, assign them methods and start \n",
    "    for x in xrange(1,11):\n",
    "        connections[x-1], childPipe=Pipe()\n",
    "        threads.append(Process(target=add, args=(\"fold\"+str(x)+\"/*.wav\",childPipe)))         \n",
    "        threads[x-1].start()\n",
    "    \n",
    "    ## wait for threads to finish, get data\n",
    "    for x,y in zip(threads,connections):\n",
    "        tD, tL = zip(*y.recv())\n",
    "        data.append((tD,tL))\n",
    "\n",
    "\n",
    "    \n",
    "## create hdf5 file and fill it with data\n",
    "## format is wholeTracks/fold[NUMBER]/[trackID] and keeps info about spectrogram, as well as class number\n",
    "## in attributes of dataset\n",
    "\n",
    "with h5py.File(\"wholeTracks.hdf5\") as f:\n",
    "    fold = 1\n",
    "    \n",
    "    for x in data:        \n",
    "        \n",
    "        grp = f.create_group(\"fold\"+str(fold))\n",
    "            \n",
    "        index = 0\n",
    "        tracks, cls = (x)\n",
    "        for track, cl in zip(tracks,cls):\n",
    "                \n",
    "            dset = grp.create_dataset(str(index),data=track)\n",
    "            dset.attrs['class']=cl\n",
    "            index +=1\n",
    "                \n",
    "        fold += 1        \n",
    "\n",
    "    f.close()\n",
    "    \n",
    "print \"I'm done, time was:\" , time.time()-ts\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splits data to train and test arrays, optional tune.\n",
    "# arrays are given in form of trainData, trainLabels...\n",
    "# method shall be fed with step between windows (equivalent to their width) and lists of folds that shall create \n",
    "# train, (tune), test arrays\n",
    "\n",
    "# train and tune arrays split tracks into windows of widht = spltStep, test array preserves whole track\n",
    "\n",
    "def split (splitStep, *data):\n",
    "    \n",
    "    with h5py.File(\"wholeTracks.hdf5\") as f:\n",
    "        \n",
    "        #no tune set\n",
    "        if len(data) == 2:\n",
    "            trainData, trainLabels, testData, testLabels = [],[],[],[]\n",
    "            \n",
    "            #create train arrays\n",
    "            for fold in data[0]:\n",
    "                grp = f['fold' + str(fold)]\n",
    "                \n",
    "                for track in grp.keys():\n",
    "                    \n",
    "                    tempTrack = grp[track][()]\n",
    "                    classNumber = grp[track].attrs['class']\n",
    "                    \n",
    "                    iterator = 0\n",
    "                    while iterator + splitStep <= tempTrack.shape[1]:\n",
    "                        trainData.append(tempTrack[: ,iterator : iterator + splitStep])\n",
    "                        trainLabels.append(classNumber)\n",
    "                        iterator += splitStep\n",
    "            \n",
    "            #create test arrays         \n",
    "            for fold in data[1]:\n",
    "                grp = f['fold' + str(fold)]\n",
    "                \n",
    "                for track in grp.keys():\n",
    "                    \n",
    "                    testData.append(grp[track][()])\n",
    "                    testLabels.append(grp[track].attrs['class'])\n",
    "                    \n",
    "            return trainData, trainLabels, testData, testLabels\n",
    "                 \n",
    "        # with tune set\n",
    "        elif len(data) == 3:\n",
    "            trainData, trainLabels, tuneData, tuneLabels, testData, testLabels = [],[],[],[],[],[]\n",
    "            \n",
    "            # create train arrays\n",
    "            for fold in data[0]:\n",
    "                grp = f['fold' + str(fold)]\n",
    "                \n",
    "                for track in grp.keys():\n",
    "                    \n",
    "                    tempTrack = grp[track][()]\n",
    "                    classNumber = grp[track].attrs['class']\n",
    "                    \n",
    "                    iterator = 0\n",
    "                    while iterator + splitStep <= tempTrack.shape[1]:\n",
    "                        trainData.append(tempTrack[: ,iterator : iterator + splitStep])\n",
    "                        trainLabels.append(classNumber)\n",
    "                        iterator += splitStep\n",
    "                        \n",
    "            # create tune arrays\n",
    "            for fold in data[1]:\n",
    "                grp = f['fold' + str(fold)]\n",
    "                \n",
    "                for track in grp.keys():\n",
    "                    \n",
    "                    tempTrack = grp[track][()]\n",
    "                    classNumber = grp[track].attrs['class']\n",
    "                    \n",
    "                    iterator = 0\n",
    "                    while iterator + splitStep <= tempTrack.shape[1]:\n",
    "                        tuneData.append(tempTrack[: ,iterator : iterator + splitStep])\n",
    "                        tuneLabels.append(classNumber)\n",
    "                        iterator += splitStep\n",
    "            \n",
    "            # create test arrays\n",
    "            for fold in data[2]:\n",
    "                grp = f['fold' + str(fold)]\n",
    "                \n",
    "                for track in grp.keys():\n",
    "                    \n",
    "                    testData.append(grp[track][()])\n",
    "                    testLabels.append(grp[track].attrs['class'])\n",
    "            \n",
    "            return trainData, trainLabels, tuneData, tuneLabels, testData, testLabels\n",
    "\n",
    "        else:\n",
    "            raise NameError(\"Wrong number of inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicts classes on whole database or specified fold from database\n",
    "def predictOnDataBase(model, splitStep, *data):\n",
    "    with h5py.File(\"wholeTracks.hdf5\") as f:\n",
    "        ## prepare list of folds to work on\n",
    "        if len(data) == 0:\n",
    "            grps = []\n",
    "            for grp in f:\n",
    "                grps.append(f[grp])\n",
    "        else:\n",
    "            if type(data[0]) is list:\n",
    "                for fold in data[0]:\n",
    "                    grps.append(f['fold' + str(fold)])\n",
    "            else:\n",
    "                for fold in data:\n",
    "                    grps.append(f['fold' + str(fold)])\n",
    "        \n",
    "        ## assign scores to every file in fold        \n",
    "        for grp in grps:\n",
    "            for clip in grp.keys():\n",
    "                clip = grp[clip]\n",
    "                if 'predictions' in clip.attrs:\n",
    "                    del clip.attrs['predictions']\n",
    "                \n",
    "                temp = clip[()]\n",
    "                trackToPredict = []\n",
    "                iterator = 0\n",
    "                    \n",
    "                ## if clip is too short to predict even 1 window, expand it\n",
    "                if temp.shape[1]<16:\n",
    "                    t = temp.shape[1]\n",
    "                    b = np.zeros((64,16))\n",
    "                    b[:, :-16+t]= temp\n",
    "                    trackToPredict.append(b)\n",
    "                else:\n",
    "                    ## iterate through clip and split it into windows\n",
    "                    while iterator + splitStep <= temp.shape[1]:\n",
    "                        trackToPredict.append(temp[: ,iterator : iterator + splitStep])\n",
    "                        iterator += splitStep\n",
    "                    \n",
    "                ## prepare clip as a corrent CNN input and predict probabilities\n",
    "                trackToPredict= np.array(trackToPredict)\n",
    "                trackToPredict = np.expand_dims(trackToPredict, axis=3)\n",
    "                predicted = model.predict(trackToPredict, batch_size=1, verbose=2)\n",
    "\n",
    "                ## predicted is a matrix of probabilities, where each row has 10 probabilities of being\n",
    "                ## specific class, each row represents one predicted window\n",
    "                \n",
    "                ## to predictions append list of best prediction of class for each window\n",
    "                ## predicted is majority vote over all windows (but voted using probabilities, not classes)\n",
    "                clip.attrs['predictions']=np.argmax(predicted,axis=1)\n",
    "                clip.attrs['predicted']=predicted.sum(axis=0).argmax()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prints score and accuracy matrix for whole dataset or for given folds\n",
    "def getScores(*data):\n",
    "    scores = np.zeros((10,10))\n",
    "    with h5py.File(\"wholeTracks.hdf5\") as f:\n",
    "        grps = []\n",
    "        ## prepare folds to print scores for\n",
    "        if not data:\n",
    "            for grp in f:\n",
    "                grps.append(f[grp])\n",
    "        else:\n",
    "            if type(data[0]) is list:\n",
    "                for fold in data[0]:\n",
    "                    grps.append(f['fold' + str(fold)])\n",
    "            else:\n",
    "                for fold in data:\n",
    "                    grps.append(f['fold' + str(fold)])\n",
    "\n",
    "        for grp in grps:\n",
    "            for clip in grp.keys():\n",
    "                clip = grp[clip]\n",
    "\n",
    "                scores[clip.attrs['predicted'],clip.attrs['class']] += 1\n",
    "                \n",
    "                \n",
    "            \n",
    "    ## returns confusion matrix (where rows are predicted classes and columns are actuall classes)\n",
    "    ## as well as accuracy \n",
    "    return scores, scores.trace()/scores.sum()\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OUTDATED - REPLACED BY HDF5\n",
    "## KEPT JUST IN CASE, TO BE DELETED\n",
    "\n",
    "from multiprocessing import Process, Lock, Pipe,Event\n",
    "import time\n",
    "from keras import utils\n",
    "\n",
    "\n",
    "allData,allLabels=[],[]\n",
    "trainData,trainLabels= [],[]\n",
    "tuneData,tuneLabels=[],[]\n",
    "testData,testLabels=[],[]\n",
    "#function to extract data using multiprocessing\n",
    "def add(x,c):\n",
    "    tempdata,templabels = [],[]\n",
    "    if int(x[4])<9:\n",
    "        try:\n",
    "            int(x[5])\n",
    "        except:\n",
    "            #split for training set - loses information about which clip batch comes from \n",
    "            for file in glob.glob(x):\n",
    "                appendSounds(tempdata, templabels, file)\n",
    "        else:\n",
    "            #split for testing set - presumes batches of sound within clip\n",
    "            for file in glob.glob(x):\n",
    "                appendTracks(tempdata, templabels, file)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        #split for testing set - presumes batches of sound within clip\n",
    "        for file in glob.glob(x):\n",
    "            appendTracks(tempdata, templabels, file)\n",
    "            \n",
    "    c.send(zip(tempdata, templabels))\n",
    "    del tempdata,templabels\n",
    "        \n",
    "ts = time.time()\n",
    "\n",
    "#doing actual multiprocessing extraction\n",
    "if __name__ == '__main__':\n",
    "    threads= []\n",
    "    connections=[0]*10\n",
    "    lock = Lock()\n",
    "    for x in xrange(1,11):\n",
    "        connections[x-1], childPipe=Pipe()\n",
    "        threads.append(Process(target=add, args=(\"fold\"+str(x)+\"/*.wav\",childPipe)))         \n",
    "        threads[x-1].start()\n",
    "    fold = 1\n",
    "    for x,y in zip(threads,connections):\n",
    "        tD, tL = zip(*y.recv())\n",
    "        if fold <= 6:\n",
    "            trainData += tD\n",
    "            trainLabels += tL\n",
    "        elif fold <= 8 :\n",
    "            tuneData += tD\n",
    "            tuneLabels += tL\n",
    "        else:\n",
    "            testData += tD\n",
    "            testLabels += tL\n",
    "        fold+=1\n",
    "        \n",
    "    #save data into numpy array, change classes label using onehot encoding\n",
    "    trainData, trainLabels = np.array(trainData), np.array(utils.to_categorical(trainLabels, num_classes=10))\n",
    "    tuneData, tuneLabels = np.array(tuneData), np.array(utils.to_categorical(tuneLabels, num_classes=10))\n",
    "    #testData, testLabels = np.array(testData), np.array(utils.to_categorical(testLabels, num_classes=10))\n",
    "    \n",
    "    print \"I'm done, time was:\" , time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7322/7322 [==============================] - 0s\n",
      "23987/23987 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Tune score: 0.294 Train score: 0.351 Learning rate: 0.008000 L2 reg: 0.002070\n"
     ]
    }
   ],
   "source": [
    "## NO PROPER DATA PREPARATION FOR THIS PART RIGHT NOW, GIVES POOR SCORES ANYWAY\n",
    "## PROCEED TO CNN PART\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from random import uniform\n",
    "from math import pow\n",
    "rates2 = []\n",
    "\n",
    "#standard NN - was fine tuned for another example, outdated right now\n",
    "\n",
    "LR,L2= 0.008,0.00207\n",
    "net = Sequential()\n",
    "net.add(Dense(512, activation='relu', input_dim=1024,\n",
    "             kernel_regularizer=regularizers.l2(L2)))\n",
    "net.add(Dropout(0.5))\n",
    "net.add(Dense(256, activation='relu',\n",
    "             kernel_regularizer=regularizers.l2(L2)))\n",
    "net.add(Dropout(0.3))\n",
    "net.add(Dense(64, activation='relu',\n",
    "             kernel_regularizer=regularizers.l2(L2)))\n",
    "net.add(Dropout(0.1))\n",
    "net.add(Dense(10, activation='softmax'))\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "           optimizer = SGD(lr=LR,decay=1e-6, momentum=0.9,nesterov=True),\n",
    "           metrics = ['accuracy'])\n",
    "\n",
    "net.fit(trainData, trainLabels, epochs = 100, batch_size=128, verbose=0)\n",
    "rates2.append([net.evaluate(tuneData,tuneLabels, batch_size=16384)[1],\n",
    "             net.evaluate(trainData,trainLabels, batch_size=16384)[1],\n",
    "             LR,L2])\n",
    "print (\"Tune score: %.3f Train score: %.3f Learning rate: %f L2 reg: %f\" %(rates2[-1][0],rates2[-1][1],LR, L2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## prepare data for CNN training\n",
    "\n",
    "## split folds into train, tune and test sets\n",
    "trainData, trainLabels, tuneData, tuneLabels, testData, testLabels = split(16, [1,2,3,4,5,6,7],[8],[9,10])\n",
    "\n",
    "## lists to np arrays\n",
    "trainData=np.array(trainData)\n",
    "trainLabels=np.array(trainLabels)\n",
    "tuneData=np.array(tuneData)\n",
    "tuneLabels=np.array(tuneLabels)\n",
    "\n",
    "\n",
    "## add 3rd dim - channel required by conv layers\n",
    "trainData=np.expand_dims(trainData,axis=3)\n",
    "tuneData=np.expand_dims(tuneData,axis=3)\n",
    "\n",
    "from keras import utils\n",
    "\n",
    "## classes to vector - one hot encode\n",
    "trainLabels = np.array(utils.to_categorical(trainLabels, num_classes=10))\n",
    "tuneLabels = np.array(utils.to_categorical(tuneLabels, num_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5s - loss: 1.6157 - acc: 0.4540\n",
      "Epoch 2/100\n",
      "3s - loss: 1.0621 - acc: 0.6383\n",
      "Epoch 3/100\n",
      "3s - loss: 0.8567 - acc: 0.7188\n",
      "Epoch 4/100\n",
      "3s - loss: 0.7230 - acc: 0.7644\n",
      "Epoch 5/100\n",
      "3s - loss: 0.6257 - acc: 0.7959\n",
      "Epoch 6/100\n",
      "3s - loss: 0.5482 - acc: 0.8220\n",
      "Epoch 7/100\n",
      "3s - loss: 0.4948 - acc: 0.8405\n",
      "Epoch 8/100\n",
      "3s - loss: 0.4461 - acc: 0.8552\n",
      "Epoch 9/100\n",
      "3s - loss: 0.4114 - acc: 0.8642\n",
      "Epoch 10/100\n",
      "3s - loss: 0.3856 - acc: 0.8714\n",
      "Epoch 11/100\n",
      "3s - loss: 0.3533 - acc: 0.8822\n",
      "Epoch 12/100\n",
      "3s - loss: 0.3333 - acc: 0.8885\n",
      "Epoch 13/100\n",
      "3s - loss: 0.3156 - acc: 0.8944\n",
      "Epoch 14/100\n",
      "3s - loss: 0.2981 - acc: 0.9028\n",
      "Epoch 15/100\n",
      "3s - loss: 0.2758 - acc: 0.9052\n",
      "Epoch 16/100\n",
      "3s - loss: 0.2677 - acc: 0.9093\n",
      "Epoch 17/100\n",
      "3s - loss: 0.2525 - acc: 0.9138\n",
      "Epoch 18/100\n",
      "3s - loss: 0.2496 - acc: 0.9168\n",
      "Epoch 19/100\n",
      "3s - loss: 0.2294 - acc: 0.9224\n",
      "Epoch 20/100\n",
      "3s - loss: 0.2208 - acc: 0.9253\n",
      "Epoch 21/100\n",
      "3s - loss: 0.2145 - acc: 0.9277\n",
      "Epoch 22/100\n",
      "3s - loss: 0.2027 - acc: 0.9292\n",
      "Epoch 23/100\n",
      "3s - loss: 0.1932 - acc: 0.9348\n",
      "Epoch 24/100\n",
      "3s - loss: 0.1852 - acc: 0.9374\n",
      "Epoch 25/100\n",
      "3s - loss: 0.1767 - acc: 0.9399\n",
      "Epoch 26/100\n",
      "3s - loss: 0.1758 - acc: 0.9395\n",
      "Epoch 27/100\n",
      "3s - loss: 0.1663 - acc: 0.9438\n",
      "Epoch 28/100\n",
      "3s - loss: 0.1604 - acc: 0.9437\n",
      "Epoch 29/100\n",
      "3s - loss: 0.1533 - acc: 0.9472\n",
      "Epoch 30/100\n",
      "3s - loss: 0.1508 - acc: 0.9480\n",
      "Epoch 31/100\n",
      "3s - loss: 0.1425 - acc: 0.9503\n",
      "Epoch 32/100\n",
      "3s - loss: 0.1373 - acc: 0.9525\n",
      "Epoch 33/100\n",
      "3s - loss: 0.1327 - acc: 0.9539\n",
      "Epoch 34/100\n",
      "3s - loss: 0.1325 - acc: 0.9532\n",
      "Epoch 35/100\n",
      "3s - loss: 0.1304 - acc: 0.9558\n",
      "Epoch 36/100\n",
      "3s - loss: 0.1296 - acc: 0.9539\n",
      "Epoch 37/100\n",
      "3s - loss: 0.1212 - acc: 0.9571\n",
      "Epoch 38/100\n",
      "3s - loss: 0.1177 - acc: 0.9589\n",
      "Epoch 39/100\n",
      "3s - loss: 0.1168 - acc: 0.9596\n",
      "Epoch 40/100\n",
      "3s - loss: 0.1078 - acc: 0.9625\n",
      "Epoch 41/100\n",
      "3s - loss: 0.1112 - acc: 0.9597\n",
      "Epoch 42/100\n",
      "3s - loss: 0.1087 - acc: 0.9616\n",
      "Epoch 43/100\n",
      "3s - loss: 0.1017 - acc: 0.9638\n",
      "Epoch 44/100\n",
      "3s - loss: 0.1001 - acc: 0.9649\n",
      "Epoch 45/100\n",
      "3s - loss: 0.0953 - acc: 0.9660\n",
      "Epoch 46/100\n",
      "3s - loss: 0.0890 - acc: 0.9679\n",
      "Epoch 47/100\n",
      "3s - loss: 0.0908 - acc: 0.9692\n",
      "Epoch 48/100\n",
      "3s - loss: 0.0940 - acc: 0.9668\n",
      "Epoch 49/100\n",
      "3s - loss: 0.0909 - acc: 0.9677\n",
      "Epoch 50/100\n",
      "3s - loss: 0.0868 - acc: 0.9695\n",
      "Epoch 51/100\n",
      "3s - loss: 0.0867 - acc: 0.9692\n",
      "Epoch 52/100\n",
      "3s - loss: 0.0794 - acc: 0.9723\n",
      "Epoch 53/100\n",
      "3s - loss: 0.0800 - acc: 0.9725\n",
      "Epoch 54/100\n",
      "3s - loss: 0.0820 - acc: 0.9711\n",
      "Epoch 55/100\n",
      "3s - loss: 0.0807 - acc: 0.9710\n",
      "Epoch 56/100\n",
      "3s - loss: 0.0768 - acc: 0.9723\n",
      "Epoch 57/100\n",
      "3s - loss: 0.0753 - acc: 0.9743\n",
      "Epoch 58/100\n",
      "3s - loss: 0.0758 - acc: 0.9737\n",
      "Epoch 59/100\n",
      "3s - loss: 0.0762 - acc: 0.9739\n",
      "Epoch 60/100\n",
      "3s - loss: 0.0727 - acc: 0.9749\n",
      "Epoch 61/100\n",
      "3s - loss: 0.0705 - acc: 0.9757\n",
      "Epoch 62/100\n",
      "3s - loss: 0.0667 - acc: 0.9777\n",
      "Epoch 63/100\n",
      "3s - loss: 0.0706 - acc: 0.9747\n",
      "Epoch 64/100\n",
      "3s - loss: 0.0652 - acc: 0.9770\n",
      "Epoch 65/100\n",
      "3s - loss: 0.0656 - acc: 0.9769\n",
      "Epoch 66/100\n",
      "3s - loss: 0.0667 - acc: 0.9778\n",
      "Epoch 67/100\n",
      "3s - loss: 0.0630 - acc: 0.9776\n",
      "Epoch 68/100\n",
      "3s - loss: 0.0642 - acc: 0.9778\n",
      "Epoch 69/100\n",
      "3s - loss: 0.0626 - acc: 0.9781\n",
      "Epoch 70/100\n",
      "3s - loss: 0.0604 - acc: 0.9778\n",
      "Epoch 71/100\n",
      "3s - loss: 0.0566 - acc: 0.9803\n",
      "Epoch 72/100\n",
      "3s - loss: 0.0563 - acc: 0.9807\n",
      "Epoch 73/100\n",
      "3s - loss: 0.0597 - acc: 0.9780\n",
      "Epoch 74/100\n",
      "3s - loss: 0.0562 - acc: 0.9809\n",
      "Epoch 75/100\n",
      "3s - loss: 0.0551 - acc: 0.9807\n",
      "Epoch 76/100\n",
      "3s - loss: 0.0531 - acc: 0.9814\n",
      "Epoch 77/100\n",
      "3s - loss: 0.0548 - acc: 0.9807\n",
      "Epoch 78/100\n",
      "3s - loss: 0.0532 - acc: 0.9809\n",
      "Epoch 79/100\n",
      "3s - loss: 0.0514 - acc: 0.9819\n",
      "Epoch 80/100\n",
      "3s - loss: 0.0532 - acc: 0.9815\n",
      "Epoch 81/100\n",
      "3s - loss: 0.0503 - acc: 0.9817\n",
      "Epoch 82/100\n",
      "3s - loss: 0.0498 - acc: 0.9822\n",
      "Epoch 83/100\n",
      "3s - loss: 0.0482 - acc: 0.9834\n",
      "Epoch 84/100\n",
      "3s - loss: 0.0497 - acc: 0.9826\n",
      "Epoch 85/100\n",
      "3s - loss: 0.0487 - acc: 0.9833\n",
      "Epoch 86/100\n",
      "3s - loss: 0.0497 - acc: 0.9825\n",
      "Epoch 87/100\n",
      "3s - loss: 0.0514 - acc: 0.9823\n",
      "Epoch 88/100\n",
      "3s - loss: 0.0494 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "3s - loss: 0.0462 - acc: 0.9834\n",
      "Epoch 90/100\n",
      "3s - loss: 0.0485 - acc: 0.9820\n",
      "Epoch 91/100\n",
      "3s - loss: 0.0439 - acc: 0.9843\n",
      "Epoch 92/100\n",
      "3s - loss: 0.0436 - acc: 0.9849\n",
      "Epoch 93/100\n",
      "3s - loss: 0.0428 - acc: 0.9856\n",
      "Epoch 94/100\n",
      "3s - loss: 0.0431 - acc: 0.9847\n",
      "Epoch 95/100\n",
      "3s - loss: 0.0404 - acc: 0.9860\n",
      "Epoch 96/100\n",
      "3s - loss: 0.0435 - acc: 0.9843\n",
      "Epoch 97/100\n",
      "3s - loss: 0.0408 - acc: 0.9859\n",
      "Epoch 98/100\n",
      "3s - loss: 0.0395 - acc: 0.9860\n",
      "Epoch 99/100\n",
      "3s - loss: 0.0391 - acc: 0.9862\n",
      "Epoch 100/100\n",
      "3s - loss: 0.0402 - acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f217c450a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D,BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#CNN working on batches of image, accuracy up to 72%\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(padding = (1,1), input_shape=(64, 16, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D(padding = (1,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(ZeroPadding2D(padding = (1,1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainData, trainLabels, batch_size=512, epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67332123412\n"
     ]
    }
   ],
   "source": [
    "## AS WELL OUTDATED, SCORES ARE NOW BASED ON PREDICTIONS SAVED IN HDF5 FILE\n",
    "\n",
    "#final scoring function. isnt used in training.\n",
    "#CNN predicts classes for all parts of clip and sums probablities, chooses best\n",
    "#scores is confusion matrix\n",
    "scores = np.zeros((10,10))\n",
    "for track,label in zip(testData,testLabels):\n",
    "    tempD =[]\n",
    "    iterator = 0\n",
    "    ## if track is too short for even one window to predict, fill it up with zeros to one window size\n",
    "    if track.shape[1]<16:\n",
    "        t = track.shape[1]\n",
    "        b = np.zeros((64,16))\n",
    "        b[:, :-16+t]= track\n",
    "        tempD.append(b)\n",
    "    while (iterator+16<=track.shape[1]):\n",
    "        tempD.append(track[:,iterator:iterator+16])\n",
    "        iterator+=16\n",
    "    tempD= np.array(tempD)\n",
    "    tempD = np.expand_dims(tempD, axis=3)\n",
    "    predicted = model.predict(tempD, batch_size=1, verbose=2)\n",
    "    scores[predicted.sum(axis=0).argmax(),label]+=1\n",
    "\n",
    "accuracy = scores.trace()/scores.sum()    \n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  60.    0.    0.    4.    1.    0.    1.    2.    1.    0.]\n",
      " [   0.   39.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  23.    3.  174.   45.    8.   25.    0.    1.   36.   18.]\n",
      " [   0.    2.   10.  135.   11.    1.   14.    1.   15.    0.]\n",
      " [  29.    3.    5.    5.  119.    1.    1.   42.    2.    1.]\n",
      " [   0.    0.    0.    3.    0.  126.    0.    1.    3.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.   43.    0.    0.    0.]\n",
      " [  68.   10.    5.    3.   43.   20.    0.  131.    1.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.  105.    0.]\n",
      " [  20.    8.    6.    5.   18.    9.    4.    0.    2.  181.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD8CAYAAAA11GIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe77052e0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "## print scores and graphic version\n",
    "## confusion matrix, x - actual class, y - predicted class\n",
    "print scores\n",
    "normscores =normalize(scores,norm='l1' ,axis=0)\n",
    "plt.imshow(normscores)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some charts used in finetuning of previous NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3599b7eed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rates[:,2],rates[:,0],'ro')\n",
    "plt.axis([0.001,0.01,0.35,0.5])\n",
    "plt.show()\n",
    "#128 batch - f(learning_Rate)=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f352f5d63d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rates1[:,3],rates1[:,0],'ro')\n",
    "plt.axis([0.0001,0.01,0.4,0.5])\n",
    "plt.show()\n",
    "#128 batch - f(L2 lambda)=score, lr=0.0038"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
