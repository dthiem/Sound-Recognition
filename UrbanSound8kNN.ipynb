{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from matplotlib.pyplot import specgram\n",
    "import tensorflow as tf\n",
    "import math\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sound:\n",
    "    def __init__(self, fp):\n",
    "        X, sr = sf.read(fp)\n",
    "        sound = np.array(X)\n",
    "        # librosa operates on (lenght, channels) matrices, wheras soundfile gave us (channels, lenght) \n",
    "        # so we transpose\n",
    "        sound = np.transpose(sound)\n",
    "        sound = librosa.core.to_mono(sound)\n",
    "        # resample so every wave has same sampling rate\n",
    "        sound = librosa.core.resample(sound, sr, 10000)\n",
    "        \n",
    "        # set class number\n",
    "        self.classNumber = int(fp.split(\"/\")[1].split(\"-\")[1])\n",
    "        # set wave - sound amp in time\n",
    "        self.wave = sound\n",
    "        # compute and set mel spectrogram\n",
    "        self.mel = librosa.feature.melspectrogram(sound, sr=10000, hop_length=506)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    countNetwoks=0\n",
    "    def __init__(self,numin=None,numout=None,hiddenlayers=None,learningrate=None,arrtrain=None,arrtest=None,neural=None):\n",
    "        NeuralNetwork.countNetwoks+=1\n",
    "        self.myId=NeuralNetwork.countNetwoks\n",
    "        if neural!=None:\n",
    "            self.numIn=neural.numIn\n",
    "            self.numOut=neural.numOut\n",
    "            self.hiddenLayers=neural.hiddenLayers[:]\n",
    "            self.learningRate=neural.learningRate\n",
    "            if numin!=None:\n",
    "                self.numIn = numin\n",
    "            if numout!= None:\n",
    "                self.numOut= numout\n",
    "            if hiddenlayers!= None:\n",
    "                self.hiddenLayers=hiddenlayers[:]\n",
    "            if learningrate!= None:\n",
    "                self.learningRate=learningrate\n",
    "        else:\n",
    "            self.numIn=numin\n",
    "            self.numOut=numout\n",
    "            self.hiddenLayers = hiddenlayers\n",
    "            self.learningRate = learningrate\n",
    "    def train(self,arrtrain,arrtest=None):\n",
    "        prepareNet(self.numIn,self.numOut,self.hiddenLayers,self.learningRate,arrtrain,self.myId)\n",
    "        if arrtest!= None:\n",
    "            self.scores = testNet(arrtest, self.myId)\n",
    "            self.mainScore = self.scores.trace()/self.scores.sum()\n",
    "    def test(self,arrtest):\n",
    "            self.scores = testNet(arrtest, self.myId)\n",
    "            self.mainScore = self.scores.trace()/self.scores.sum()        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-90:\n",
      "Process Process-82:\n",
      "Process Process-84:\n",
      "Process Process-83:\n",
      "Process Process-85:\n",
      "Process Process-81:\n",
      "Process Process-89:\n",
      "Traceback (most recent call last):\n",
      "Process Process-88:\n",
      "Traceback (most recent call last):\n",
      "Process Process-86:\n",
      "Process Process-87:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c9d3be3c6709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"=====\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "    e.wait()\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "    e.wait()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    e.wait()\n",
      "    e.wait()\n",
      "    e.wait()\n",
      "    e.wait()\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    e.wait()\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    e.wait()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"<ipython-input-13-c9d3be3c6709>\", line 13, in add\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    self._wait_semaphore.acquire(True, timeout)\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "    self._wait_semaphore.acquire(True, timeout)\n",
      "    self._wait_semaphore.acquire(True, timeout)\n",
      "    e.wait()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 246, in wait\n",
      "    self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    self._cond.wait(timeout)\n",
      "    self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python2.7/multiprocessing/synchronize.py\", line 337, in wait\n",
      "    self._cond.wait(timeout)\n",
      "    self._wait_semaphore.acquire(True, timeout)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Lock, Pipe,Event\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "arrtrain = []\n",
    "arrtuning=[]\n",
    "arrtest=[]\n",
    "def add(x,c,e):\n",
    "    temp = []\n",
    "    #for file in glob.glob(x):\n",
    "        #temp.append(Sound(file))\n",
    "    e.wait()\n",
    "    #c.send(1)\n",
    "    del temp\n",
    "        \n",
    "ts = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threads= []\n",
    "    connections=[0]*10\n",
    "    events = [Event()]*11\n",
    "    for x in xrange(5,11):\n",
    "        events[x].clear()\n",
    "    lock = Lock()\n",
    "    for x in xrange(1,11):\n",
    "        connections[x-1],childPipe=Pipe()\n",
    "        threads.append(Process(target=add, args=(\"fold\"+str(x)+\"/*.wav\",childPipe,events[x-1])))         \n",
    "        threads[x-1].start()\n",
    "    fold = 1\n",
    "    for x,y in zip(threads,connections):\n",
    "        #if fold < 8:\n",
    "        #    arrtrain.extend(y.recv())\n",
    "        #elif fold == 8 :\n",
    "        #    arrtuning.extend(y.recv())\n",
    "        #else:\n",
    "        #    arrtest.extend(y.recv())\n",
    "        for event in events:\n",
    "            print event.is_set()\n",
    "        x.join()\n",
    "        print \"=====\"\n",
    "        events[fold].set()\n",
    "        fold+=1\n",
    "    print \"I'm done, time was:\" , time.time()-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2.4 Build inference graph.\n",
    "def mnist_inference(sounds, numin,numout,hiddenLayers):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder.\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    hidden=[]\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([numin, hiddenLayers[0]],\n",
    "                                stddev=1.0 / math.sqrt(float(numin))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hiddenLayers[0]]),\n",
    "                             name='biases')\n",
    "        hidden.append(tf.nn.relu(tf.matmul(sounds, weights) + biases))\n",
    "    \n",
    "    for i in xrange(1,len(hiddenLayers)):\n",
    "        with tf.name_scope('hidden'+str(i+1)):\n",
    "            weights = tf.Variable(\n",
    "                tf.truncated_normal([hiddenLayers[i-1], hiddenLayers[i]],\n",
    "                                    stddev=1.0 / math.sqrt(float(hiddenLayers[i-1]))),\n",
    "                name='weights')\n",
    "            biases = tf.Variable(tf.zeros([hiddenLayers[i]]),\n",
    "                                 name='biases')\n",
    "            hidden.append(tf.nn.relu(tf.matmul(hidden[i-1], weights) + biases))\n",
    "        \n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hiddenLayers[-1], numout],\n",
    "                                stddev=1.0 / math.sqrt(float(hiddenLayers[-1]))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([numout]),\n",
    "                             name='biases')\n",
    "        logits = tf.matmul(hidden[-1], weights) + biases\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"inference.pbtxt\", as_text=True)\n",
    "    return logits\n",
    "\n",
    "# 2.5 Build training graph.\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    \"\"\"Build the training graph.\n",
    "\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES].\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values in the\n",
    "          range [0, NUM_CLASSES).\n",
    "        learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The Op for calculating loss.\n",
    "    \"\"\"\n",
    "    # Create an operation that calculates loss.\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"train.pbtxt\", as_text=True)\n",
    "\n",
    "    return train_op, loss\n",
    "\n",
    "# 2.6 Build the complete graph for feeding inputs, training, and saving checkpoints.\n",
    "def prepareNet(numin,numout,hiddenLayers, learningRate,trainset,saveId):\n",
    "    mnist_graph = tf.Graph()\n",
    "    with mnist_graph.as_default():\n",
    "        # Generate placeholders for the images and labels.\n",
    "        images_placeholder = tf.placeholder(tf.float32)                                       \n",
    "        labels_placeholder = tf.placeholder(tf.int32)\n",
    "        tf.add_to_collection(\"images\", images_placeholder)  # Remember this Op.\n",
    "        tf.add_to_collection(\"labels\", labels_placeholder)  # Remember this Op.\n",
    "\n",
    "        # Build a Graph that computes predictions from the inference model.\n",
    "        logits = mnist_inference(images_placeholder,numin,numout,hiddenLayers)\n",
    "        tf.add_to_collection(\"logits\", logits)  # Remember this Op.\n",
    "\n",
    "        # Add to the Graph the Ops that calculate and apply gradients.\n",
    "        train_op, loss = mnist_training(logits, labels_placeholder, learningRate)\n",
    "\n",
    "        # Add the variable initializer Op.\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Uncomment the following line to see what we have constructed.\n",
    "        # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "        #                      \"/tmp\", \"complete.pbtxt\", as_text=True)\n",
    "    \n",
    "    # 2.7 Run training for MAX_STEPS and save checkpoint at the end.\n",
    "    with tf.Session(graph=mnist_graph) as sess:\n",
    "        # Run the Op to initialize the variables.\n",
    "        sess.run(init)\n",
    "        losses = []\n",
    "        counter=0\n",
    "        # Start the training loop.\n",
    "        for x in trainset:\n",
    "            # Read a batch of images and labels.\n",
    "            #images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "            mel_feed, labels_feed = [],[]\n",
    "            for z in xrange(x.mel.shape[1]/10):\n",
    "                mel_feed.append(x.mel[:,z*10:(z+1)*10].flatten())\n",
    "                labels_feed.append(x.classNumber)\n",
    "            #print np.array(mel_feed).shape, \" \", np.array(labels_feed).shape\n",
    "\n",
    "\n",
    "            # Run one step of the model.  The return values are the activations\n",
    "            # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "            # inspect the values of your Ops or variables, you may include them\n",
    "            # in the list passed to sess.run() and the value tensors will be\n",
    "            # returned in the tuple from the call.\n",
    "            if not (len(labels_feed)==0):\n",
    "                _, loss_value = sess.run([train_op, loss],\n",
    "                                         feed_dict={images_placeholder: np.array(mel_feed),\n",
    "                                                    labels_placeholder: np.array(labels_feed)})\n",
    "                losses.append(loss_value)\n",
    "            # Print out loss value.\n",
    "            counter +=1\n",
    "            #if counter % 1000 == 0:\n",
    "                #print('Step %d: loss = %.2f' % (counter, loss_value))\n",
    "\n",
    "\n",
    "\n",
    "        # Write a checkpoint.\n",
    "        #checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "        #saver.save(sess, checkpoint_file, global_step=step)\n",
    "        checkpoint_file = os.path.join(\"/tmp/sound\", 'checkpoint')\n",
    "        saver.save(sess, checkpoint_file,global_step=saveId)\n",
    "        #plt.plot(losses)\n",
    "\n",
    "def testNet(testingset,saveId):\n",
    "\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            os.path.join(\"/tmp/sound\", \"checkpoint-\"+str(saveId)+\".meta\"))\n",
    "        saver.restore(\n",
    "            sess, os.path.join(\"/tmp/sound\", \"checkpoint-\"+str(saveId)))\n",
    "\n",
    "\n",
    "        # Retrieve the Ops we 'remembered'.\n",
    "        logits = tf.get_collection(\"logits\")[0]\n",
    "        images_placeholder = tf.get_collection(\"images\")[0]\n",
    "        labels_placeholder = tf.get_collection(\"labels\")[0]\n",
    "        # Add an Op that chooses the top k predictions.\n",
    "\n",
    "        eval_op = tf.nn.top_k(logits)\n",
    "\n",
    "        scores = np.zeros((10,10))\n",
    "        for x in testingset:\n",
    "            good, total = 0, 0\n",
    "            temp = []\n",
    "            for z in xrange(x.mel.shape[1]/10):\n",
    "                mel_feed, labels_feed = [],[]\n",
    "                mel_feed.append(x.mel[:,z*10:(z+1)*10].flatten())\n",
    "                labels_feed.append(x.classNumber)\n",
    "                mel_feed, labels_feed = np.array(mel_feed), np.array(labels_feed)\n",
    "\n",
    "                # Run evaluation.\n",
    "                #images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "                prediction = sess.run(eval_op,\n",
    "                                      feed_dict={images_placeholder: mel_feed,\n",
    "                                                 labels_placeholder: labels_feed})\n",
    "                #print type(labels_feed[0]), type(prediction.indices[0][0])\n",
    "                temp.append(prediction.indices[0][0])\n",
    "                #if labels_feed[0] == prediction.indices[0][0]:\n",
    "                #   good+=1\n",
    "                #total +=1\n",
    "            if temp:\n",
    "                scores[labels_feed[0],max(set(temp), key=temp.count)]+=1\n",
    "            #if good*2 >= total:\n",
    "             #   print labels_feed, \" : \", good, \"/\", total\n",
    "            #print count\n",
    "        return scores\n",
    "        #counter = 0\n",
    "        #for x in scores:\n",
    "        #    print \"Class %d: %.2f  Quantity: %d\" %(counter, x[counter]/np.sum(x), np.sum(x))\n",
    "        #    counter +=1\n",
    "        #print \"Final score: \", scores.trace()/scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findLearningRate(neural,learnValues,arrtrain,arrtune):\n",
    "    neuralNets=[]\n",
    "    for x in learnValues:\n",
    "        neuralNets.append(NeuralNetwork(learningrate=x, neural=neural))\n",
    "    for x in neuralNets:\n",
    "        x.train(arrtrain,arrtune)\n",
    "        print \"Learning rate:\", x.learningRate, \"score:\", x.mainScore\n",
    "    bestNet,bestScore=0,0\n",
    "    for i in xrange (len(neuralNets)):\n",
    "        if bestScore<neuralNets[i].mainScore:\n",
    "            bestScore=neuralNets[i].mainScore\n",
    "            bestNet=i\n",
    "    return neuralNets[bestNet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0001 score: 0.370744010088\n",
      "Learning rate: 0.0002 score: 0.395964691047\n",
      "Learning rate: 0.0003 score: 0.409836065574\n",
      "Learning rate: 0.0004 score: 0.379571248424\n",
      "Learning rate: 0.0005 score: 0.341740226986\n",
      "Learning rate: 0.0006 score: 0.383354350567\n",
      "Learning rate: 0.0007 score: 0.287515762926\n",
      "Learning rate: 0.001 score: 0.305170239596\n",
      "[[  23.    0.    5.    0.    4.   31.    0.   79.    3.   55.]\n",
      " [   2.    0.    0.    0.    3.    5.    1.    2.   28.   12.]\n",
      " [   1.    0.  117.    0.   11.    5.    0.   10.   46.   10.]\n",
      " [   2.    0.   50.   16.    6.   13.    0.    1.   85.   21.]\n",
      " [   2.    0.   32.    3.   86.    9.    7.   32.   18.   10.]\n",
      " [   1.    0.    1.    0.   23.   94.    0.   19.   16.   28.]\n",
      " [   1.    0.   40.    0.    4.    2.   10.    0.    0.    6.]\n",
      " [   0.    0.   18.    0.  128.    1.    0.   17.   13.    1.]\n",
      " [   1.    0.   72.    1.   11.    1.    0.   14.   64.    1.]\n",
      " [   2.    0.   27.    1.   25.    7.    0.   33.   42.   63.]]\n",
      "0.299877600979\n"
     ]
    }
   ],
   "source": [
    "d= NeuralNetwork(1280,10,[1000,600,170])\n",
    "bestNet=findLearningRate(d,[0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.001],arrtrain,arrtuning)\n",
    "bestNet.test(arrtest)\n",
    "print bestNet.scores\n",
    "print bestNet.mainScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.    0.   91.    3.    3.   30.    0.   16.    0.   43.]\n",
      " [   1.   11.   11.   11.    4.    0.    0.    2.    9.    4.]\n",
      " [   0.    0.  178.    2.    7.    0.    0.    7.    4.    2.]\n",
      " [   4.    0.   85.   60.   25.    1.    0.    0.   13.    6.]\n",
      " [   3.    0.   52.    2.   87.    0.    1.   35.    2.   17.]\n",
      " [   0.    0.   45.    0.    3.   72.    0.   42.    9.   11.]\n",
      " [   2.    0.   46.    0.    3.    0.    8.    0.    0.    4.]\n",
      " [   0.    0.   29.    0.  117.    3.    0.   15.    0.   14.]\n",
      " [   0.    0.  104.    3.    7.    0.    0.    2.   45.    4.]\n",
      " [   0.    0.   57.   10.   30.    1.    0.    2.    4.   96.]]\n",
      "0.358629130967\n"
     ]
    }
   ],
   "source": [
    "e = NeuralNetwork(1280,10,[1000,600,170],0.0003)\n",
    "e.train(arrtrain,arrtest)\n",
    "print e.scores\n",
    "print e.mainScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2.4 Build inference graph.\n",
    "def mnist_inference(sounds, hidden1_units, hidden2_units, hidden3_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder.\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([1280, hidden1_units],\n",
    "                                stddev=1.0 / math.sqrt(float(1280))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]),\n",
    "                             name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(sounds, weights) + biases)\n",
    "    # Hidden 2\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden1_units, hidden2_units],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden1_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]),\n",
    "                             name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "        \n",
    "    # Hidden 3\n",
    "    with tf.name_scope('hidden3'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden2_units, hidden3_units],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden2_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden3_units]),\n",
    "                             name='biases')\n",
    "        hidden3 = tf.nn.relu(tf.matmul(hidden2, weights) + biases)\n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden3_units, 10],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden3_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([10]),\n",
    "                             name='biases')\n",
    "        logits = tf.matmul(hidden3, weights) + biases\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"inference.pbtxt\", as_text=True)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.5 Build training graph.\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    \"\"\"Build the training graph.\n",
    "\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES].\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values in the\n",
    "          range [0, NUM_CLASSES).\n",
    "        learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The Op for calculating loss.\n",
    "    \"\"\"\n",
    "    # Create an operation that calculates loss.\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"train.pbtxt\", as_text=True)\n",
    "\n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-a1665a13dd9a>:21 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Build the complete graph for feeding inputs, training, and saving checkpoints.\n",
    "mnist_graph = tf.Graph()\n",
    "with mnist_graph.as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder = tf.placeholder(tf.float32)                                       \n",
    "    labels_placeholder = tf.placeholder(tf.int32)\n",
    "    tf.add_to_collection(\"images\", images_placeholder)  # Remember this Op.\n",
    "    tf.add_to_collection(\"labels\", labels_placeholder)  # Remember this Op.\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist_inference(images_placeholder,\n",
    "                             1000,\n",
    "                             600, \n",
    "                             170)\n",
    "    tf.add_to_collection(\"logits\", logits)  # Remember this Op.\n",
    "\n",
    "    # Add to the Graph the Ops that calculate and apply gradients.\n",
    "    train_op, loss = mnist_training(logits, labels_placeholder, 0.0001)\n",
    "\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"complete.pbtxt\", as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: loss = 2.42\n",
      "Step 2000: loss = 1.88\n",
      "Step 3000: loss = 2.58\n",
      "Step 4000: loss = 3.27\n",
      "Step 5000: loss = 1.86\n",
      "Step 6000: loss = 2.32\n",
      "Step 7000: loss = 1.98\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8E9eZN/Cfbsb32GAIGBcoSelmMby7dnh335cm6W7d\ntCGUd5u8L8nuNpv0LYGkQC6l4X5LSBYnpGVTDI1J01xLaJoEAjSXYhJKbhCw24C5gwFzMeArsiVf\npDln/5AsbEmWpbGk0Yx/388nwZJmznlmJD06c+bMGZOUUoKIiAzHrHUAREQUG0zwREQGxQRPRGRQ\nTPBERAbFBE9EZFBM8EREBsUET0RkUEzwREQGxQRPRGRQTPBERAZl1TqACxcuqFovJycHdXV1UY4m\ndhhvbOkpXj3FCjDeWFIba25ubljLsQVPRGRQTPBERAbFBE9EZFBM8EREBsUET0RkUGGNohFCYMOG\nDaiursbChQvhdDpRUlKCxsZG5OXlYcaMGbBarTh06BBeffVVSCkxZcoUTJw4MdbxExFRD3ptwQsh\nsHTpUtTU1KDz5k9btmzBmDFjsHLlSthsNuzatQtCCJSWluLnP/85li1bho0bN8LpdMZ8A4iIKLhe\nW/BmsxlLly7F8ePHsXnzZgDAwYMHcf/99wMACgsL8dlnn+GGG25ASkoKcnJyAACjRo3CiRMnMH78\n+G7llZWVoaysDABQXFzsWz7iwK1W1etqgfHGlp7iTcRYpasDDfPuR8aPH0LSuMJuryVivKHoKd5Y\nxxpWF01SUlK3x3a7Henp6QCAtLQ0NDc3o7m5GWlpab5l0tLSYLfbA8oqKipCUVGR77HaCxL0dDED\nwHhjTU/xJmKssuYsxKnjaFz3NCwr1nV7LRHjDUVP8SbkhU4ZGRlwOBwAAIfDgYyMDKSnp3frknE4\nHMjMzFRTPBERRYGqBJ+fn4/y8nIAQHl5OfLz8zF06FA4nU7U1dXB6XTi9OnTuP7666MaLBERhU/V\nXDRTpkxBSUkJFixYgOHDh+Pmm2+G2WzG9OnT8eyzz0JKibvvvhupqanRjpeIiMIUdoIfO3Ysxo4d\nCwBITU3F3Llzgy5TXFwcveiIiEg1XuhERGRQTPBERAbFBE9EZFBM8EREBsUET0RkUEzwREQGxQRP\nRGRQTPBERAbFBE9EZFBM8EREBsUET0RkUEzwREQGxQRPRGRQTPBERAbFBB9D4ouPIQ/s0zoMIuqn\nVN3wg8Ijf7saEoDlhS1ah0JE/RBb8EREBsUET0RkUEzwREQGxQRPRGRQTPBERAbFBE9EZFBM8ERE\nBsUET0RkUEzwREQGxQRPRGRQTPBERAbFBJ8gZPnnkB3tWodBRAbCBJ8A5MkjEM8XQ/7+Ra1DISID\nYYJPBE4HAEA2XNY4EOq3pNQ6AooBJngiIoNSNR+8lBIvvfQSTp06BZfLhR/96EfIzc3FmjVr0Nra\nirFjx+Kee+6JdqxEFCsmk9YRUAyoSvCHDx9GfX09VqxYgZMnT2L9+vXIy8tDUVERJk6ciKeeegqV\nlZXIz8+PdrxERBQmVV002dnZuHz5MlpaWlBTU4O8vDxUVlaisLAQAFBYWIgDBw5ENVAiIoqMqhb8\nsGHD8LWvfQ0rVqzAxYsXsWTJEnz55ZdITk4GAKSmpqK6ujroumVlZSgrKwMAFBcXIycnR13gVqvq\ndePlkvffnJyckPG2Z2aiCUCSLQnZCbJNeti/Xekp3kSM1d3agnoAFoslILZEjDcUPcUb61hVJfh9\n+/ahra0NTz/9NKqqqvDcc88hNTUVbW1tSE5OhtPpREZGRtB1i4qKUFRU5HtcV1enKvCcnBzV68Zb\nXV1dyHil3Q4A6HB1JMw26Wn/AvqKNxFjlU2NAABFUQJiS8R4Q9FTvGpjzc3NDWs5VV00tbW1yM7O\nBgAMGTIEbrcb+fn5KC8vBwCUl5dj3LhxaoomIqIoUdWCv+WWW7BmzRosWbLEN4pmzJgxKCkpwdat\nWzF27FieYCUi0piqBJ+amop58+YFPL9s2bI+B0RERNHBC52IiAyKCZ6IyKCY4ImIDIoJnojIoJjg\niYgMigmeiMigmOCJiAyKCZ6IeMMPg2KCJyIyKCZ4IuINPwyKCZ6IyKCY4ImIDIoJnojIoJjgiYgM\nigmeiMigmOCJiAyKCZ6IyKCY4ImIDIoJnojIoJjgiYgMigmeiMigmOCJiAyKCZ6IyKCY4ImIDIoJ\nnojIoJjgiYh3dDIoJngiIoNigici3tHJoJjgiYgMigmeiMigDJ3gZZsTsqlB6zCIiDRh6AQvHn8Y\n4rH7tA4Dss2pdQhE1A9Z1a6oKAo2b96MPXv24MYbb8TkyZNRUlKCxsZG5OXlYcaMGbBaVRcfHXWX\ntK2/kyK0joCI+iHVLfjS0lKcPXsWjz/+OKZOnYotW7ZgzJgxWLlyJWw2G3bt2hXNOImIKEKqEvzl\ny5exZ88ePPjgg0hJSQEAHDx4EAUFBQCAwsJCVFZWRi9KIiKKmKo+lKqqKlitVqxatQoulwvf+973\nYLfbkZ6eDgBIS0tDc3Nz0HXLyspQVlYGACguLkZOTo66wK3WXtft7KBRW0dfddY/aNDAkPG2Z2ai\nCUCSLQnZGsXqL5z9m0j0FG8ixupubUE9AIvFEhBbIsYbip7ijXWsqjvJCwoKMHPmTNjtdsyZMwfZ\n2dlwOBwYOHAgHA4HMjIygq5XVFSEoqIi3+O6ujpV9efk5IS9rto6oqW+vgGD0zN7jEPa7QCADleH\n5rF2imT/JgI9xZuIscqmRgCec2v+sSVivKHoKV61sebm5oa1nKoumtGjR+Ps2bNQFAU2mw0mkwnj\nxo1DeXk5AKC8vBz5+flqiiYioihR1YIfMmQIbr75ZixZsgSKouDf//3fMWHCBJSUlGDBggUYPnw4\nbr755mjHSkREEVDdRTNp0iRMmjSp23Nz587tc0BERBQdhr7QiYioP2OCjwvOtU1E8ccET0S84YdB\nMcHHBefaJp3gvPCGwgRPRFexJW8oTPBExJa7QTHBExEZFBM8EZFBMcETERkUEzwRkUExwccFRyYQ\nUfwxwRMRGRQTPBGRQTHBxwXHGBNR/DHBExEZFBM8EZFBMcETERkUEzwRkUExwRMRGRQTPBFxmmCD\nYoKPC355SCc4bbChMMET0VVsyRsKEzwRseVuUEzwREQGxQQfF2wdEVH8McETUb8mdu+E2P2x1mHE\nhG4TvHC0QPzueciOdq1DISIdky/+EvLF1VqHERO6TfCOP7wEufM9yF0faB0KEVFC0m2ChxCefzmq\ni4goKP0meCIiCkn/CV5KyPparaPoBQ8ziCj+dJ/g5fbNEPN/AnmhWutQiIgSSp8SfENDA2bPno3N\nmzfD7XZj7dq1WLBgAZ555hk4nc5oxRhaU4Pn37pL8amPiEgnVCf4jo4OrFu3Dtdddx0AYNeuXbDZ\nbFi5ciXGjBmDrVu3Ri1II3CfPwPx+Q6twyCifsSqdsUNGzbgtttuw8mTJwEAlZWVmDhxIgCgoKAA\nL7zwAu66666A9crKylBWVgYAKC4uRk5Ojqr6W/zmzsjMzMQAv7I62/Rq6+irzvoHDRyE2h/fDigK\ncqYE7pP2zEw0AUiyJSFbo1j9Wa1WzfabGnqKNxFjdbe2oB6AxWIJiC0R4w0l0ni1zBOx3reqEnxV\nVRVaWlpQWFjoS/DNzc1IS0sDAKSlpcFutwddt6ioCEVFRb7HdXV1akLAAL9Z7+x2O0w9lKW2jmip\nb2gAFKXHWKR3X3W4OjSPtVNOTk7CxBIOPcWbiLHKpkYAgKIoAbElYryhqI1Xi21UG2tubm5Yy6lK\n8Pv27cP58+exfPly1NbWwmQyYfDgwb5+d4fDgczMTDVFExFRlKhK8FOnTsXUqVMBAG+++SaSkpKQ\nmZmJffv2oaCgABUVFcjPz49qoEQUQ5wH3pCiNkzy5ptvhsvlwoIFC3D06FH84Ac/iFbRRBQvnBfe\nUFSfZO3U2ZIHgJkzZ/a1OINi64h0gi15Q9H9hU5EFAVsuRuSbhO8sDdpHQJRQpJuN5T7p0Bsf1fr\nUEhjukzwsqEObX/+UOswqJ+Tba1ahxCc9x4JcusbGgdCWtNlgkdTvdYRUD8n9n4CMfsuyOqTWodC\n1CN9JngirVVWAADk2VMaBxICT5j2e0zwccETWBRHPGFKXvpM8PwAJyzZfAWSM3sSJYQ+j4Mn6kr8\n7B4AgOWFLRpHQkT6bMETEVGvmODjgie7iCj+mOCJjIrtin6PCZ7IaDgGgbyY4ImIDIoJnsiw2EfT\n3zHB+5FXGiEb9HN7MqKo4FWvhsRx8H7Ez+8FwHHcZAQqOuN5EaGh6LQFr7cPobp45Vd7eTRBfcBW\neX+n0wTfP4iSFRD/+XOtw0go4p1XIP74ptZhJLg+NIDYVWMo7KJJdFcatI4gocj33/b8cfvU0AtS\nZNg1Y0hswccFW0WkAbbG+z0meCIigzJMgpft7VqHQJRY2O3S7+kzwQf73LbY4x5Gfybb26E8PT+x\n72jU37GLpt/TZ4In7VUdAU4cgnjzRa0jIX9suZMXE3yUSSkhPtsB2ebUOhQi6uc4TDLaqo5Cvvwc\ncOQrrSMhUkW6XEBTPUyDh2odCvURW/DR1t4KwDOnDZEm+tj3Ll8tgVg4vV8fhUq3G+KDtz0/djrG\nBB8X2vSJio+2QXzxsSZ1k37JgxWePzr678g0+ecPIN9+BfJPm7QOpU/02UWT0CeREic2+cZ6zx//\n65+0DYTCJk8eAQCYrvsbjSPp57xH4r5/dYot+AhIKSH+tAnS2RLpmjGJh/RLNtVDHigPeF4Uz4Uo\nnhutWqJUDumVgRK8hPzrbkihxK6KI/sh//AS5O+ej10d1C+IlXMhfvW41mFQb3T+G6mqi+by5ctY\nv3492tvb4XK5MH36dIwYMQKlpaU4d+4csrOzMWvWLKSmpkY73h7Jii8gj+yH6Y57YbrtzthU4urw\n1NUaxsmnGF5kIl0u4PIFmIaPjFkdFGMNtVpH0B0vijIkVS34rKwsTJs2DStWrMD3v/99vPPOO9i1\naxdsNhtWrlyJMWPGYOvWrdGONbTOUStaf3E6zw/EMsG/UQqxfDZkU33M6qAwJWRi7ENMCX1+SwM6\n3x2qEnxSUhKGDvWMkXU4HMjKykJlZSUKCwsBAAUFBaisrIxelP2QUvJkj6/J44c8f4RzJEGkViL+\ndlFE+jSK5tixY9i+fTuWLVuGdevWIS0tDQCQlpYGuz343DBlZWUoKysDABQXFyMnJyfiel1X6uA/\nS7rFaoUCIDk5GZneMi95X4ukjlDrtGdmoglAUpIN2T2U2X7NNWgCYLPZ0DmCNkvp8MUbslxbkq/c\nS1996Xvdf506iwUKgOysbKCjFdLRDNs3/jaibemN1WoNuV7ndibZuu+LvtQZjp7K7y3eaLuSPABt\nADIyMpASYb1W69WvnX/M0dh/otUBz3GsKexy3K3NqAdgMZshzWYIAAMHDoQle1Dc921fRRpvsH3u\nSEtDC4CUlFRkxHDbY71vVSf4U6dOYe3atZg3bx6ys7ORnp4Op9PTonQ4HMjMzAy6XlFREYqKinyP\n6+oivyWdbGoKeE5xuwEAbW1t6PArU00dwdaR3h+tjg5Xj2XKK1cAAK4uF0g0zPlxeOW6OoK+7v+c\nonhOJDc2NUIsnQkg9D1k1Wx/Tk5OyPU6t7PDFXxfqKkzEv7l9xZvtIk2zxjx5pYWOCKst+sXuqeY\n+7ItvguUpAy7nM7vlKIogBAAgIbGBpgUGfd921dq4+26jnA4AACtrU60x3Db1caam5sb1nKqumgU\nRUFJSQkeffRRX0Xjxo3Dvn37AAAVFRXIz89XU7Q+JGS/KxFRd6pa8GfOnMHly5fx4ouemQQtFgsW\nL16Mw4cPY8GCBcjKysLs2bOjGihRuKSUgKLAZNXndXwJg+0Y3VP1DRg9ejRee+21gOdnzpzZ54DC\no/Gp7UQZacAjiaDkhuchd74fstsqepUl4HuQgCGRNgx0oVMchfpSJ0ry1xmpKJBK8IvUZHsbZM25\n8Mva+X60wurf+FHWPcMleNlQC3mhOuzlxbu/g3L/lPAWjiR5x6NlZ6AfE7FoBsSDwS9QE79eCbH0\npz3+AGjKQO9BAB4J6J7hEjz274VYNivsxeW234dfdqyTdmUFpKM5/OUTsXtArfrLgBTBXzuy3/Ov\nkbY3luzeUWbcX/2e8RJ8nMn2Nii/XAJ56UJ0yvvrnqiUo7p+lwtS9JBoSRfE4geiU1CcDk6UFY9C\nbNkQn8r6GeMk+Jqzsa8j2OH4wb8Ah7+CeOvlnpeJZzx9JH56J+Sra1StG3ZXF1FX1Scht27UOgpD\n0meCDyOvSc0PT+NQf4y2UX62I/J1nI4YRNI3nZ8BsefPUO6fAll3qZc1VFUS/TIThQE3TVYdhay9\nqHUYcaPPBB+OqqNaR9CvJPLUt/LLXZ5/D/M+uf2dWPkYxMLpWocRN8ZN8N6pfQFA/PHNuFQp7U0Q\na5+KS10AEmsEh/dORNEmdu8E+jB6RkoJ7N/r+fvVkihF1UUivQfRZuBN6y+Mm+C7kB//MboFVpZD\nVlYE1vPhpvjO8JgI3QMxjkG++MvgzztbIM/3MhxWSl/rPd7kxfOQ1VWa1N0lCo3rTyzad9vGX79I\n8LEgnlse+uKbWH6Y4tBqdP7xD1B+sRjy/JmY1xW+q/tUFM+DWB7GcNgr/vOOxodY8iDEikd6Xa6v\nSUds2whlaYyuIDdaPtR4hJoWmOD7QPznHG0q7jx5GMF4/0g1/2Y1cGS/58Yi3pk6g9KqiyKsUVNG\ny1CB5LsbojOCLIFbt7L8cygrH+vzj6Fs0M+MmNGi0wSfIJ2Dbfq447py/xTI5iuQleWevx3Bbxou\nTx0L/nwvY5Rlc/C5/6MuzjlIVlZAeehuSO/7LL7cFTgCI4EToypdf7AT5Gsmni+O+qAJsX4VlOXG\nnxBRpwlev9QkQ3nU7+5YIVrNUkpIe2PgC1XHIN5/y/P3udPB1/3T5uCF9jK8UPzsRyFf1yux+XXP\nORVvV5x84VmIJ38W3UoS+Qci0ULr677q8rWRez8BEqr7MTaY4GOlh8+ifOuliIsSzy70K6TnD7r8\n4G2IOff2OtZX1l+OOA7dkQBOn4humU6/ox+jjaKR0njb1I8xwXtF/Qx7T/OqCAXy0F8hz56C2Ptp\n2MUpKx+DCGOYn6ws9/wRcPPxq9snD1ZAzJ8GuS/8+hND5O+R3PtJDOKIoP6WOHVfBa08gmW7JvU+\nfBekoxnK7LsgTxxSXUaI0mNQZuJVGU2GTfBi4wvxrfDoge6PexgXLnfvhFi9FOKJhyHXPxN++VVH\nIT/5k+fvIC0s5TnvhUbHDvZalPR20chTx8OvP0LKc8tjVraeiEfVdV/F8vMrz50Ob8ZVNQ35k0eA\ntlaI995SsTJFm2ETfLf+tSuNkN6EK08cgnh9XWCL/dL5MAoN8YlvdUCejdO452AtrM6WeyTrxLJ5\nEuQ6gbiLYf+2bA//BLsMeYIweIxyx9bey1V5dCAefyi8EViJ1nrVIh6d91YZN8H76fzCiKfnQ/75\ng4DXxZKfhlNK6Jcjmeq3s8SzpyJeR50usXt/DOSZk92nJ070vtc4npCU9ZeBMyH678s/9y7Ye0xi\n5WNRisqv3F6PDlTur758DuI90kmIkBeUyYovILtc1d7f6DLBywP7olBI4CdRHvpr38uNNIyKzyNf\nqYcvoDzQSyvet6B3248egHh6fuDzcSAvXQg6vl4ePwTpdsW+frc7ZDeFeG1tzGNIFNLlgvRO5+B5\nItGa7l7BvrPbN0OseATyxOHA144fgvj1Ssg/eAc2qNmsMNYRn27v/apqjegywSOCOzb1LPCdE6uX\nRqHcCKOIYgte1YRf8Zhm2Y9saoBY/ADk738T8Jp4Zj7k26/2sGLENfX8yu9/A7FsFmTAyegI6/L7\nsZXt7VAimcwqRD2y88YdqnliE3s/gbJqQY83k5FvvwzZOd11txcEZGO96tpl8xWI3/4XZHu76jL8\nSgx86sxJzyvBRoV5Rzz5XnPE5oS3fGVNeFdVa0CfCV7NIaQQkG1d5onp5Qss/vgmlFV+wxNj0SHn\nP3dNUwPER9uiX0+oROJN8nEbVeO90Er6n5jujOeLjyAvBjknIiObdEx+/lHPrx33noz2H/boWyCy\nm56I99/2tCIvngUimI5WPPDDHqdaDq/bMBTPmy7XrwKOHexxIjx5uSb48+9ugJj7Yyh16obUyrdf\n8byXX/5Z1fp9Fo0jkT5+5aWi+H4kZVO950LDr77se1xh6jcJXpZ/BjH77i5PhH7z5ebXgWOV/s/2\nUomKD5RfHXLz65BvrI+8nD4QfZnLJILJ1ZTHH4L47X9dfcLV4bkE/bTfaB5HM8SSBwPWF+tWBjwn\nKysgRQ83645iN0vXk/IyyEgl+c4rEE/Pg6qMEOzCNKDnHx+1wr3rmPf71TnkVqidz6dzn5mjlGbU\n5mtfvojtOSZ5ZH9AI0n+4bcQc3/sOSHuPdoQuz6MaRxd6TPBR+WNSqB+xhjcIi9gkjApwxpCGbFQ\nJyL9nTsN+cVHV9++uktA1dHwhwQGmc9dPLcc8v23w4+hky9hB36WpNsdWFfXBK+XG0YoCsSfNkW2\nTqszen3wnUdBJhPEWy9DlL0bnXLjKYJdIX6xGKK0+9Bn3/nCHqYHiTV9JnjNRnv0Uq/KectFyQpV\n64USeBQQ+pMqNpSGfv2Dt6FEOBpEbH839ERl0dKXOzW12APOg8htfreP8z/pe6bLEYd/Mgyj1R2w\nT0J1n7VFNv204nceyXeCEeg5cXd9/kpD9I4cOss1mSE/fAfy9y96pnl2u6E8+TMoD90dev3AAj3/\nP1YJec7v3JXKnBBsqKk8/BXkptdUlRfIG1eEXX7R0n8TvEREJ3/kgXIgyNhn2fUkZVRO/sZGyKmN\ngV7nzJdvvxLxhE/yzRchd74X0Tpx0zkj5y8WQzzxcPfX/FroYuN6dM3C8uMu2+TXxSZeeLbXqut+\nOtU/mB6X7datGIKvCykaI8E6GypNvXfNSLcLsuPq90i8vu7qi6IzwV/9voqH/w3iwTs8R36tTsjm\nK8HLdbRAeXZR0JPgYtVCiMcfDrJWQCndHwbLG67AEVvilS73JA6RamQP+0c6W3wT1MHcmeBx9Qev\nh22OBV0meLk/CicpmpsgZv2/8Or7626IXz0ecPgFePvq40g21qsa+RLvOH3iMeOmyQT3hbOQTb2P\n+Oipv777Qn6JoboKYvWy4It+8TFkeZehrmF8eYV/F4+QnvHcPUwCFxYVLUTl2UWeI4SwLvILTjz5\nM4iZnu+RtDcBXd8Db0w93bQF8Pux7Pr87p3A0QOQH3TpfgvVdRROt1KwZB1sn4cxT5M8/BXEY/d1\nf++9xMP/BvHz+7x1elOsFJCdPyY9zNoaC9a41RRNLZFfUBQgzOFfYuf7kL/7dd/rixIx98ea1i8P\n7IO8dB7IyApvhXCOtnqa1qG9LbyYPvkT6r3TOFhe2BJ62d07Yfrf3wl83umAKTWt5xWP7O/xJfF8\ncVhx9rj+8lnAdX/Tt9seSvQ+n1LzFSj3T7n6+OiBsI8QeuQ91yMvX4BY9IBfTGEk3YZekqnK0wHS\n3gR5xTvM1DdqJfCz2HVosbLyMVgWrAqvfO9V677RWP7aW7s3xpwtkU1NEiX6TPBR0O0wLIRESu6J\nQPzqib4XEmYXm5jl35URBefPQLz0XEC/unj4X2H+z/WeS/ivHR71apV5P4H5rp8A3xwXfIFekrts\ndQLtbTBlDQy+QFN90It9oqHpqbnAf8yCKb/AE8uVRsi/7oH5lu/7lglI7gBkGEcV8rMd3R6LXR8C\nzVcgD/0lcOEwznHJpnp01F6AWBgknq4XcwUTRhekPPwV5JEDQHqG53GIKSW6NsbE1o09LhdLJqnx\njQovXAhz6FYX3VohFHt/Mz5kCzaka7JhfmId5PtvXT3cttoCT1xGiXnhL7S701YcmP55MuRH2zwJ\nxu9I1nT7VMg43WAeAEx33us5NxOt8v7p9tDngq7JhuXZV3zff/PMRb6x/aYf/Cvk1jd6Xjfjmr71\nfWdmwfKLV6OWe0zTH4N5wk3IyclBXV3kd5rKzc0Nrx4meCKi+DPdPR1D7rovpglelydZzQ8u0DoE\nIqI+kRtjf0GjLhM8xhVqHQERUcKLeoLftm0b5s+fj0WLFqG6OkbjwnvoVTL/1H/uGI0MHKx1BESU\n6G74HzGvIqoJ/uLFi9i5cyeeeuop3HvvvXjxxRejWbyPKWkAMu7/GUz/cnU+bPP6d2H6+3+MSX0R\nGzxU6wi6syUBAEzT58L0D7d4/r7jXi0jomC8o1S0Yl7c83j1vjD98J6YlKt7pth3oES1hsrKSowf\nPx4WiwVjxozBuXPn4I7Rpeqpk/4vTN/7oe+xyTv0zjz/6lhT8+JfesYXhzLy+qjHZrr+hoDnzGEk\nffP6EHN1DB8J0x3/EXkwA3NgWfcWLC9sgXnCt2CeNsfz9213AjnXRl6el+nOCH4gxv598OdHXg/T\nv80I+pL54eWRx/Td/wPz6teDDkU0fecHEZcXT+aSN2FRsc0BLF1GPg8fCdPEosBFOq8VGD4Slhe2\n+P4z9fBdyPj/V68aNa8KfdN4013TYP7la8DwkVcbFrf+C8wPzodp6k/C3gzTtDkwP7EWphu/FfY6\n3YS6piES3/jbqBRjusu77SmpV5+bGHg9RrRFdRTNpk2bIKXEHXfcAQCYPXs2nnjiCWRnZ/uWKSsr\nQ1lZGQCguLgYHR3q7rZitVrhdrsh29sgrjTCMmSY7zXXySOwDBoCs3fMsNLUAPM12eg4UA7LoMFw\nnz0N6/ARkELAOmI04OqA+/RJKE31sGQNgiU3D6LZDnNWNuByQ7a3on33n2G7YTxMtiSYswai7bMd\ngKIg6e/+J0wpqXCdPAJ0dMA6YjQseaOgXKiG6/ghJP/TJJhMJlgAtB4oh3S7kPR3/wD3mZOAyQTr\n174O9+njsFybC3NaBoTTAeXiOUBKmGxJcFdXwfbNfFi8PxDC0eJ5XQiY0jJgstmg1F6EZcgwz7Su\nUgImE6TFD72oAAAJdElEQVSjBZbB18I8aAjMaek97se2zz+CbG9H8sR/hilpAIS9CaKpARaLBcKW\nBNHUAOFsgW1MPtynjsEyZJgvFtneBunqgCktA+7TJwBImFLSIBrqYM0bCelyQdibYPv6NyA72iHb\n2tD+l92wjvg6rHlfh8lm87w/jfWQLc0wpaQCQoEpLQPmtHS4z56G0lALa+7XYBk81Pe+SkWBbG+D\nZdAQmAYMgFJfi6QhQ6F4x0lLKeE6UA7LiNGQba2wDvWMa5eKG6KxAZacId32QUflX2AZMhTC6fB8\nZtxuuC9Uw3b9DTANSIb77ClYBg+FcvkCZHs7LDnXwnX8IKy5I2DJGwnnlt8j+ZZb0b7vMySNnwDZ\nYodoaYbJYoFlWJ7nfXG74a6ugiVvJKwWC1orK2D75jhYhg6HbG+DbeR1AAD3udNQLtXAmjcSHZUV\ncJ06hgF//4+wjrwOrsP7YR39TUhnC2CxQLa3w5w1EO4zJ2GyWOE+dwqpU/4VgIRyvhrWEaMhFQWu\n44c8+1oRMCUnwzpiNJRLF2DKuAZmv0QoWh0QV5pgTkn1vH+OZqRc9004yr+A9Wtfh2Vgjm8fd26T\nUnsRpqQBGFDQ/Qhaujo8302/hoRnXRdkqxOmjGvgPn0cUBTYrr8BSmM9LNmDui/f1uqZkdJi9Xzm\n2pwwp2ei7dMdMKWket4zVwcwIBnWEV+Hxe2CzMiC4p0G2X3+DCyDhsAyfATgckGpr4X7zAko9bWw\n5o6AbG+FZVgeTBYrLMNHQNivwJSUBNnR4fkcnj4J0WL3fKaFgDk1Ha7Txz3xXjzn+cw3NUB4py5I\nGn8jRP1lWIblob1iNwZM+BZMZjOUSxdgHjQESu1FWIfldctjkUpKSgpruagm+LKyMtTU1OCeezyH\nZNOmTcPzzz8Pq7Xn66nUDJMEoHr8qFYYb2zpKV49xQow3liK9Tj4qHbRjB07Fl999RUURcGxY8cw\nfPjwkMmdiIhiJ6rZd9iwYfj2t7+NhQsXwmq1YsaM4P2rREQUe1FvXk+ePBmTJ0+OdrFERBQhfV7o\nREREvWKCJyIyKCZ4IiKDYoInIjIozacLJiKi2NBtC37+/PlahxARxhtbeopXT7ECjDeWYh2rbhM8\nERGFxgRPRGRQluXLly/XOgi1Ro8erXUIEWG8saWnePUUK8B4YymWsfIkKxGRQbGLhojIoJjgiYgM\nSpdz+W7btg2ffvopLBYLZsyYgREjRmgajxACGzZsQHV1NRYuXAin04mSkhI0NjYiLy8PM2bMgNVq\nxaFDh/Dqq69CSokpU6Zg4sSJAIDXX38dBw8eRHJyMmbPno2BAwfGJM7Lly9j/fr1aG9vh8vlwvTp\n0zFixAiUlpbi3LlzyM7OxqxZs5Camorq6mqUlpZCURR861vf8k0gF899f+HCBaxduxYmkwkDBgzA\nI488AovFkpD7tlNDQwOWLVuG73znO5g8eXLC7lsAWL58OVwuF8xmMwoLC3Hrrbcm9L5VFAWbN2/G\nnj17cOONN2Ly5MkJG+/evXuxZYvnzllutxtnzpzBb37zm/jHK3WmpqZGzpkzR7rdbnn06FG5dOlS\nTeNRFEUuWrRIPvPMM/LJJ5+UUkr5xhtvyE2bNkkppSwtLZU7duyQiqLIhx56SNbW1kqHwyFnzZol\nHQ6H3L9/v2+9Tz/9VK5ZsyZmsba3t8uamhoppZQff/yxXLVqldyxY4csLS2VUkq5adMmuXHjRiml\nlEuWLJFHjx6VbrdbzpkzR9bU1MR93yuKIltbW6WUUr7yyivy3XffTdh9K6Vn/65YsUKuXr1abtq0\nKaH3rZRSLly4UHZ0dPgeJ/K+lVLKtWvXytWrV0un06mLeDu99tprctOmTZrEq7sumnje9zUcZrMZ\nS5cuxaRJk3zPHTx4EAUFnhsoFxYWorKyEpcuXUJKSgpycnKQmpqKUaNG4cSJE6isrERhYaFv2QMH\nDsQs1qSkJAwd6rndnsPhQFZWVrf6CwoKUFlZCbfbjQsXLmDMmDGwWCwYP348Kisr477vzWYzkpOT\nIYRAQ0MDsrKyEnbfAsCGDRtw2223+e62k8j7FgCcTieOHDkCu90OIHE/t4Dn6HPPnj148MEHkZKS\nkvDxdmpqasKXX36J22+/XZN4dZfgm5ubkZ5+9R6jqampaG5u1jCiwPsj2u12X4xpaWlobm5Gc3Mz\n0tKu3v8yLS0Ndru92/PJyclwOp0xj/fYsWPYvn077rzzzm71d40pNfXqzYG7bkO89/3p06fx8MMP\n4+zZsygoKEjYfVtVVYWWlhbflxJAwu/bSZMmoby8HAsWLMDevXsTdt8Cnv1rtVqxatUqLFu2DJ9/\n/nlCx9tp+/btuPXWW2Gz2TSJV3d98BkZGaipqfE9bm1tRUZGhoYRBcrIyIDD4cDAgQPhcDiQkZGB\n9PT0bm+Sw+FAZmYm0tPT4XA4AABtbW3dvvyxcOrUKaxduxbz5s1DdnZ2t7i6xuQfa2erNN77ftSo\nUVizZg0+/PBDlJaWJuy+3bdvH86fP4/ly5ejtrYWJpMJgwcPTuh9+93vfhcAMGHCBGzcuDFh922n\ngoICzJw5E3a7HXPmzEF2dnZCxwsAu3fvxpIlSwBokxd014LXw31f8/PzUV5eDgAoLy9Hfn4+hg4d\nCqfTibq6OjidTpw+fRrXX389xo0b123ZcePGxSwuRVFQUlKCRx991JdUxo0bh3379gEAKioqkJ+f\nD5vNhtzcXBw7dgyKomD//v3Iz8+P+74XQvj+Hjp0KJqbmxN2306dOhUrV67E8uXLccstt6CoqAg3\n3XRTwu5bRVF8f7e2tiI1NTVh9y3guRjo7NmzUBQFNpsNJpMpIIZEihcA6urqYLPZkJWVBUCbvKDL\nC522bduGTz75xHffV61H0QCe/sDNmzdj0aJF3UbRDB8+HA888ACsVisOHjyI1157LejZ8srKSqSk\npGDWrFkYNGhQTGKsqqrCsmXLMGrUKACAxWLB4sWLfSM9srKyMHv27G4jPdxuN2666aZuIz3ite93\n796NrVu3wmKxwGQy4b777sO1116bkPu2qzfffBNJSUndRtEk2r49dOgQXn75ZdhsNiQlJWHatGnI\nzs5O6H373nvv4dNPP4WiKJg0aRImTJiQ0PFWVFRg165deOSRRwBAk7ygywRPRES9010XDRERhYcJ\nnojIoJjgiYgMigmeiMigmOCJiAyKCZ6IyKCY4ImIDIoJnojIoP4b/Ui+1yOJiBwAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa38a8dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.7 Run training for MAX_STEPS and save checkpoint at the end.\n",
    "with tf.Session(graph=mnist_graph) as sess:\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "    losses = []\n",
    "    counter=0\n",
    "    # Start the training loop.\n",
    "    for x in arrtest:\n",
    "        # Read a batch of images and labels.\n",
    "        #images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "        mel_feed, labels_feed = [],[]\n",
    "        for z in xrange(x.mel.shape[1]/10):\n",
    "            mel_feed.append(x.mel[:,z*10:(z+1)*10].flatten())\n",
    "            labels_feed.append(x.classNumber)\n",
    "        #print np.array(mel_feed).shape, \" \", np.array(labels_feed).shape\n",
    "        \n",
    "        \n",
    "        # Run one step of the model.  The return values are the activations\n",
    "        # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "        # inspect the values of your Ops or variables, you may include them\n",
    "        # in the list passed to sess.run() and the value tensors will be\n",
    "        # returned in the tuple from the call.\n",
    "        if not (len(labels_feed)==0):\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                                     feed_dict={images_placeholder: np.array(mel_feed),\n",
    "                                                labels_placeholder: np.array(labels_feed)})\n",
    "            losses.append(loss_value)\n",
    "        # Print out loss value.\n",
    "        counter +=1\n",
    "        if counter % 1000 == 0:\n",
    "            print('Step %d: loss = %.2f' % (counter, loss_value))\n",
    "                      \n",
    "    \n",
    "            \n",
    "    # Write a checkpoint.\n",
    "    #checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    #saver.save(sess, checkpoint_file, global_step=step)\n",
    "    checkpoint_file = os.path.join(\"/tmp/sound\", 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step=counter)\n",
    "    plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation = []\n",
    "for file in glob.glob(\"fold9/*.wav\"):\n",
    "    evaluation.append(Sound(file))\n",
    "for file in glob.glob(\"fold10/*.wav\"):\n",
    "    evaluation.append(Sound(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  16.    0.   89.    5.    2.   43.    9.   25.    0.   11.]\n",
      " [   1.    4.   19.    7.    4.    0.    2.    0.    2.   14.]\n",
      " [   3.    0.  161.    6.    2.    5.    0.    7.    7.    9.]\n",
      " [   1.    0.   71.   75.    9.    4.    1.    0.    9.   24.]\n",
      " [   7.    0.   51.    2.   73.    9.   11.   34.    0.   12.]\n",
      " [   0.    0.   60.    0.    0.  115.    0.    5.    0.    2.]\n",
      " [   3.    0.   45.    0.    2.    0.   12.    0.    0.    1.]\n",
      " [   0.    0.   33.    0.   85.    4.    0.   56.    0.    0.]\n",
      " [   0.    0.  104.    5.    0.    3.    0.    3.   50.    0.]\n",
      " [   0.    0.   67.   12.   10.    6.    3.    6.    3.   93.]]\n",
      "Class 0: 0.08  Quantity: 200\n",
      "Class 1: 0.08  Quantity: 53\n",
      "Class 2: 0.81  Quantity: 200\n",
      "Class 3: 0.39  Quantity: 194\n",
      "Class 4: 0.37  Quantity: 199\n",
      "Class 5: 0.63  Quantity: 182\n",
      "Class 6: 0.19  Quantity: 63\n",
      "Class 7: 0.31  Quantity: 178\n",
      "Class 8: 0.30  Quantity: 165\n",
      "Class 9: 0.47  Quantity: 200\n",
      "Final score:  0.400856793146\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    saver = tf.train.import_meta_graph(\n",
    "        os.path.join(\"/tmp/sound\", \"checkpoint-7079.meta\"))\n",
    "    saver.restore(\n",
    "        sess, os.path.join(\"/tmp/sound\", \"checkpoint-7079\"))\n",
    "\n",
    "\n",
    "    # Retrieve the Ops we 'remembered'.\n",
    "    logits = tf.get_collection(\"logits\")[0]\n",
    "    images_placeholder = tf.get_collection(\"images\")[0]\n",
    "    labels_placeholder = tf.get_collection(\"labels\")[0]\n",
    "    # Add an Op that chooses the top k predictions.\n",
    "        \n",
    "    eval_op = tf.nn.top_k(logits)\n",
    "    \n",
    "    scores = np.zeros((10,10))\n",
    "    for x in evaluation:\n",
    "        good, total = 0, 0\n",
    "        temp = []\n",
    "        for z in xrange(x.mel.shape[1]/10):\n",
    "            mel_feed, labels_feed = [],[]\n",
    "            mel_feed.append(x.mel[:,z*10:(z+1)*10].flatten())\n",
    "            labels_feed.append(x.classNumber)\n",
    "            mel_feed, labels_feed = np.array(mel_feed), np.array(labels_feed)\n",
    "\n",
    "            # Run evaluation.\n",
    "            #images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "            prediction = sess.run(eval_op,\n",
    "                                  feed_dict={images_placeholder: mel_feed,\n",
    "                                             labels_placeholder: labels_feed})\n",
    "            #print type(labels_feed[0]), type(prediction.indices[0][0])\n",
    "            temp.append(prediction.indices[0][0])\n",
    "            #if labels_feed[0] == prediction.indices[0][0]:\n",
    "            #   good+=1\n",
    "            #total +=1\n",
    "        if temp:\n",
    "            scores[labels_feed[0],max(set(temp), key=temp.count)]+=1\n",
    "        #if good*2 >= total:\n",
    "         #   print labels_feed, \" : \", good, \"/\", total\n",
    "        #print count\n",
    "    print scores\n",
    "    counter = 0\n",
    "    for x in scores:\n",
    "        print \"Class %d: %.2f  Quantity: %d\" %(counter, x[counter]/np.sum(x), np.sum(x))\n",
    "        counter +=1\n",
    "    print \"Final score: \", scores.trace()/scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff314066450>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAD7CAYAAAAsJIKcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff30b681650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normscores =normalize(scores)\n",
    "plt.imshow(normscores)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
